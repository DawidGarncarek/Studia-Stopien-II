from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import Perceptron
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, f1_score

print('Zadanie 1')
# Wczytaj zbiór danych
data = load_breast_cancer()
X, y = data.data, data.target

# Podział na dwie równe części
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)

# 1. Klasyfikator Perceptron
perceptron = Perceptron(random_state=42)
perceptron.fit(X_train, y_train)
y_pred_perceptron = perceptron.predict(X_test)

# 2. Klasyfikator Multi-Layer Perceptron
mlp = MLPClassifier(random_state=42, max_iter=1000)
mlp.fit(X_train, y_train)
y_pred_mlp = mlp.predict(X_test)

# 3. Wyznacz dokładność
accuracy_perceptron = accuracy_score(y_test, y_pred_perceptron)
accuracy_mlp = accuracy_score(y_test, y_pred_mlp)
print(f"Dokładność Perceptron: {accuracy_perceptron}")
print(f"Dokładność Multi-Layer Perceptron: {accuracy_mlp}")

# 4. Wyznacz F1-score
f1_perceptron = f1_score(y_test, y_pred_perceptron)
f1_mlp = f1_score(y_test, y_pred_mlp)
print(f"F1-score Perceptron: {f1_perceptron}")
print(f"F1-score Multi-Layer Perceptron: {f1_mlp}")

print(' ')

print('Zadanie 2')
from sklearn.metrics import precision_score, recall_score

# Model z 3 warstwami ukrytymi
mlp_3_layers = MLPClassifier(hidden_layer_sizes=(50, 50, 50), random_state=42, max_iter=1000)
mlp_3_layers.fit(X_train, y_train)
y_pred_3_layers = mlp_3_layers.predict(X_test)

accuracy_3 = accuracy_score(y_test, y_pred_3_layers)
precision_3 = precision_score(y_test, y_pred_3_layers)
recall_3 = recall_score(y_test, y_pred_3_layers)
print(f"3 warstwy - Dokładność: {accuracy_3}, Precyzja: {precision_3}, Czułość: {recall_3}")

# Model z 5 warstwami ukrytymi
mlp_5_layers = MLPClassifier(hidden_layer_sizes=(50, 50, 50, 50, 50), random_state=42, max_iter=1000)
mlp_5_layers.fit(X_train, y_train)
y_pred_5_layers = mlp_5_layers.predict(X_test)

accuracy_5 = accuracy_score(y_test, y_pred_5_layers)
precision_5 = precision_score(y_test, y_pred_5_layers)
recall_5 = recall_score(y_test, y_pred_5_layers)
print(f"5 warstw - Dokładność: {accuracy_5}, Precyzja: {precision_5}, Czułość: {recall_5}")
print(' ')

print('Zadanie 3')
from sklearn.datasets import fetch_california_housing
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error

# Wczytaj zbiór danych
data = fetch_california_housing()
X, y = data.data, data.target

# Podział na dwie równe części
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)

# Model z 3 warstwami ukrytymi
mlp_3_layers = MLPRegressor(hidden_layer_sizes=(50, 50, 50), random_state=42, max_iter=1000)
mlp_3_layers.fit(X_train, y_train)
y_pred_3_layers = mlp_3_layers.predict(X_test)

mse_3 = mean_squared_error(y_test, y_pred_3_layers)
mape_3 = mean_absolute_percentage_error(y_test, y_pred_3_layers)
print(f"3 warstwy - MSE: {mse_3}, MAPE: {mape_3}")

# Model z 5 warstwami ukrytymi
mlp_5_layers = MLPRegressor(hidden_layer_sizes=(50, 50, 50, 50, 50), random_state=42, max_iter=1000)
mlp_5_layers.fit(X_train, y_train)
y_pred_5_layers = mlp_5_layers.predict(X_test)

mse_5 = mean_squared_error(y_test, y_pred_5_layers)
mape_5 = mean_absolute_percentage_error(y_test, y_pred_5_layers)
print(f"5 warstw - MSE: {mse_5}, MAPE: {mape_5}")
print(' ')

print('Zadanie 4')
from sklearn.model_selection import cross_val_score, GridSearchCV

# Model z walidacją krzyżową
mlp_cv = MLPRegressor(hidden_layer_sizes=(50, 50, 50), random_state=42, max_iter=1000)
mse_cv = cross_val_score(mlp_cv, X, y, cv=3, scoring='neg_mean_squared_error')
mape_cv = cross_val_score(mlp_cv, X, y, cv=3, scoring='neg_mean_absolute_percentage_error')
print(f"3 warstwy - MSE (CV): {-mse_cv.mean()}, MAPE (CV): {-mape_cv.mean()}")

# Optymalizacja liczby warstw i rozmiarów
param_grid = {
    'hidden_layer_sizes': [(25,), (50,), (75,), (100,), (200,),
                           (25, 25), (50, 50), (75, 75), (100, 100), (200, 200),
                           (25, 25, 25), (50, 50, 50), (75, 75, 75), (100, 100, 100), (200, 200, 200)]
}
grid_search = GridSearchCV(MLPRegressor(random_state=42, max_iter=1000), param_grid, cv=3, scoring='neg_mean_squared_error')
grid_search.fit(X, y)

best_model = grid_search.best_estimator_
print(f"Najlepszy model: {grid_search.best_params_}")

# MSE i MAPE dla najlepszego modelu
best_mse = -cross_val_score(best_model, X, y, cv=3, scoring='neg_mean_squared_error').mean()
best_mape = -cross_val_score(best_model, X, y, cv=3, scoring='neg_mean_absolute_percentage_error').mean()
print(f"Najlepszy model - MSE: {best_mse}, MAPE: {best_mape}")
